our final discussion in basic text processing is segmenting out sentences from running text
 so how we going to send two segments out sentences things that end in! So? That's really great because those are relatively unemployed you excused that we've gotten to the end of a sentence. Unfortunately are quite ambiguous you think about it. Can be a sentence boundary but periods are also used for abbreviations like anchor doctor they're used for numbers like .02 or 4.3 so we can't assume that it. At the end of the sentence so what we need to do to solve the. Problem is build ourselves a classifier we're going to build a binary classify looks at it. And simply makes a binary yes no decision of my at the end of a
am I not at the end of a sentence to make this classifier we could use hand written rules we could use regular Expressions we could build machine learning classifiers the simplest kind of pacifier for this is a decision tree so here's a simple decision tree for deciding whether a word is an end of sentence or not so decision tree is a simple if-then procedure that asks a question and branches based on the answer to the question so we say am I in a piece of text that has a lot of blank lines after me well if so then I'm probably in the end of sentence what if there's no blank lines after me well as my final punctuation a? Or an exclamation point if so well then I'm still probably end up sends well if not that is my final punctuation of.
if it's not well I'm I'm not in a sentence
 but if I am a. Well then it depends if I'm on some long list of abbreviations like the word e t c then I'm probably not in the end of sentence I'm just too. Marking an abbreviation like dr. Reedy see but if I'm not an abbreviation then I'm the end of sentence so here's a decision tree
 you can imagine arbitrarily sophisticated decision tree features that we could use so one thing we can use is the case or it's called the word shape of the word with a. Am I in uppercase word if my a lowercase word am I all caps uppercase meaning the first letter is uppercase lower meaning it's lowercase cat meaning it's all caps Amaya number any of these kind of weird shape features can give us information and all cow
what word is very likely to be a n a f abbreviation we can look at the word with the abbreviate that with the. We can look at the word after the. If the next word starts with a capital letter that I'm likely to be the beginning.. End of sentence because the next word starts with a capital letter and we can look at lots of new features am I a long word or short word so abbreviation tend to be relatively short acronyms tend to be very short them and I can use very sophisticated features so I can say let's look at the the word I'm looking at right now take this word and ask in a corpus that I've already know where the sentence boundaries are how often is this word occur with a.
end of a sentence is the kind of word that ends a sentence is this a kind of word for example that tends to start a sentence is this the word the word that this phrase for example the words after a period very likely to be a capital t h e after. Very likely to start a sentence the space in between them so this will have a high probability of being a start of a sentence and we can use these kind of features depending on condition on each of the words again to help us in deciding what is or isn't end of sentence.
now a decision tree is just an if-then else statement so that the that that's just the definition of a decision tree is the interesting research is choosing the features so we've seen
number of features you might pick for this particular task in general the structure of the Season tree is not as often too hard to build by hand in general hand-building of decision trees is Possible only for very simple features are simple domains you might build a simple decision tree with six or seven rules like this forum for some simple tasks but it's very hard to do you have to pick the threshold for each of the numeric features I'm picking a probability as one of my features I got to have a question in the decision tree is this probability greater than some threshold data or not and I've got I said all those Speedos and so generally we use machine learning that learns the structure of the tree and learns things like the threshold for each of the questions that were asking
nonetheless the questions in a decision tree we can think of them as the kind of features that could be exploited by any other kind of classifier whether it's logistic regression svm's are neural Nets them up as far as we'll talk about it later so this in this intuition that we can build a classifier we can drive feature is that a good predictors of weather app. Is acting as an end up sending this or not and I'm going to put these features into any kind of classifier holds for whatever classify are we going to be using
